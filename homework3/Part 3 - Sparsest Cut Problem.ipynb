{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-on experiment 3:  Computing a geometric embedding for the Sparsest Cut Problem via Semidefinite Programming (20 pts)\n",
    "\n",
    "The Uniform Sparsest Cut problem (USC) aims to find a bipartition\n",
    "$(S, \\bar{S})$ of the nodes of a graph $G = (V, E)$,\n",
    "$\\vert V \\vert = p$, which minimizes the quantity $$\\frac{E(S, \\bar{S})}{\\lvert S \\rvert \\; \\lvert \\bar{S} \\rvert},$$\n",
    "where $E(S, \\bar{S})$ is the number of edges connecting $S$ and\n",
    "$\\bar{S}$, and $\\lvert S \\rvert$ is the number of nodes in $S$. This\n",
    "problem is of broad interest, with applications in areas such as VLSI\n",
    "layout design, topological design of communication networks and image\n",
    "segmentation. Relevant to machine learning, it appears as a subproblem\n",
    "in hierarchical clustering algorithms\n",
    "[@Dasgupta2016; @Chatziafratis2018].\n",
    "\n",
    "Computing such a bipartition is NP-hard and intense research has gone\n",
    "into designing efficient approximation algorithms for this problem. In\n",
    "the seminal work of [@Arora2009] an $\\mathcal{O}(\\sqrt{\\log p})$ approximation\n",
    "algorithm is proposed for solving USC, which relies on finding a\n",
    "*well-spread* $\\ell_2^2$ geometric representation of $G$ where each node\n",
    "$i\\in V$ is mapped to a vector ${\\textbf v}_i$ in $\\mathbb{R}^p$. In this\n",
    "experimental section we focus on solving the SDP that computes this\n",
    "geometric embedding.\n",
    "\n",
    "The canonical formulation of the SDP is \n",
    "\\begin{align}\n",
    "{\\boldsymbol X}^\\star \\in \\arg \\min_{ {\\boldsymbol X} } \\bigg\\{ \\langle \\boldsymbol{C}, {\\boldsymbol X} \\rangle : &~p \\; \\mathrm{Tr}({\\boldsymbol X}) -  \\mathrm{Tr}(\\mathbf{1}_{p\\times p}{\\boldsymbol X}) = \\frac{p^2}{2}, ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\longleftarrow ~~\\equiv A({\\boldsymbol X}) = \\frac{p^2}{2}  \\\\[3mm] \n",
    "& \\; {\\boldsymbol X}_{i,j} + {\\boldsymbol X}_{j,k} - {\\boldsymbol X}_{i, k} - {\\boldsymbol X}_{j,j} \\leq 0, \\; \\forall\\ i \\neq j \\neq k \\neq i\\in V, ~~~\\longleftarrow ~~\\equiv B_{i,j,k}({\\boldsymbol X}) \\in \\mathcal{K} = (-\\infty, 0] \\tag{Problem 2} \\\\[3mm]\n",
    "&~\\underbrace{\\mathrm{Tr}({\\boldsymbol X}) \\leq p, ~{\\boldsymbol X} \\in \\mathbb{R}^{p\\times p} ,~{\\boldsymbol X}\\succeq 0}_{\\mathcal{X}} \\bigg\\},~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\longleftarrow ~~ {\\boldsymbol X}  \\in \\mathcal{X} \\text{ (the SDP cone of bounded trace)} \n",
    "\\end{align}\n",
    " where $\\boldsymbol{C}$ represents the Laplacian of graph\n",
    "$G$ and ${\\boldsymbol X}_{i,j} = \\langle {\\textbf v}_{i}, {\\textbf v}_j\\rangle$ gives the geometric\n",
    "embedding of the nodes.\n",
    "\n",
    "We can rewrite the optimization\n",
    "problem <span class=\"reference\" data-target=\"Problem 2\">2</span> as $$\n",
    "    \\min_{{\\boldsymbol X} \\in \\mathcal{X}} f({\\boldsymbol X}) + g(A({\\boldsymbol X})) ~~~~~~~~\\text{ subject to } ~~~~B_{i,j,k}({\\boldsymbol X}) \\in \\mathcal{K}, \\;\\forall\\ i \\neq j \\neq k \\neq i\\in V, \\tag{Problem 3}$$\n",
    "where $f({\\boldsymbol X}) = \\langle \\boldsymbol{C}, {\\boldsymbol X} \\rangle$ and\n",
    "$g(\\cdot) = \\delta_{\\left\\{\\frac{p^2}{2}\\right\\}}(\\cdot)$ is the\n",
    "indicator function of singleton $\\left\\{\\frac{p^2}{2}\\right\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  (5 pts) How many constraints does\n",
    "    <span class=\"reference\" data-target=\"Problem 2\">Problem 2</span> have (as a function of $p$)? How does this\n",
    "    number compare to the one of\n",
    "    <span class=\"reference\" data-target=\"Problem 1\">Problem 1</span> from Part 2?\n",
    "\n",
    "    **N.B.1**: In Part 2 the constraints are expressed in matrix form,\n",
    "    while here they are listed individually. Make sure to take this into\n",
    "    account (e.g., the constraint ${\\boldsymbol X} \\geq 0$ in Part 2 is applied *for\n",
    "    each* entry).\n",
    "\n",
    "    **N.B.2**: You can respond to this question by either computing the\n",
    "    exact number of constraints, or by identifying the correct order of\n",
    "    magnitude (big-O notation).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2.  (5 pts) Express the constraints\n",
    "    in <span class=\"reference\" data-target=\"Problem 3\">Problem 3</span> in quadratic penalty form and write down\n",
    "    the corresponding penalized objective function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "3.  (10 pts) We will now observe the behavior of HCGM on three graphs\n",
    "    from the Network Repository dataset [@Rossi2015]:\n",
    "\n",
    "    -   **G1:** `mammalia-primate-association-13` with $25$ nodes,\n",
    "\n",
    "    -   **G2:** `55n-insecta-ant-colony1-day37` with $55$ nodes and\n",
    "\n",
    "    -   **G3:** `insecta-ant-colony4-day10` with $102$ nodes.\n",
    "\n",
    "    You are asked to do the following:\n",
    "    \n",
    "    - Based on your calculation in point (1), give an estimate of the\n",
    "    number of constraints for each dataset above.\n",
    "    - We provide most of the code for solving this problem below. Fill in the few missing parts, run the\n",
    "    algorithm for each dataset (you can cook your dinner in the\n",
    "    meantime)\n",
    "    - Include the generated plots in your submitted notebook. \n",
    "    - What do you notice about the running times of the algorithm for the three\n",
    "    problem instances? \n",
    "    - What are the potential bottlenecks to applying\n",
    "    this method to large graphs?\n",
    "\n",
    "    One way to address the issues you identified above, especially if\n",
    "    low accuracy suffices, is to resort to stochastic algorithms (the\n",
    "    reasoning here is similar to the one which stands behind GD vs.\n",
    "    SGD). Such an example are the methods proposed\n",
    "    in [@Vladarean2020], where the framework of HCGM is used\n",
    "    in conjunction with stochastic gradients and variance reduction for\n",
    "    alleviating some of the shortcomings of the full-batch method you\n",
    "    implemented above. A brief presentation of these methods is provided\n",
    "    in the supplementary section of Lecture 13."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r Part3_requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse.linalg import eigsh, svds, eigs\n",
    "from math import sqrt\n",
    "import scipy.io as sio\n",
    "import random\n",
    "import numpy.matlib\n",
    "import time\n",
    "from scipy.sparse import isspmatrix\n",
    "import itertools\n",
    "\n",
    "from lib.part3.helpers import *\n",
    "\n",
    "# fix the seed\n",
    "random.seed( 3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HCGM(dataset, maxit=np.int(1e3), beta0=1e2):\n",
    "    # Dataset setup\n",
    "    from argparse import Namespace\n",
    "    args = Namespace()\n",
    "    Problem = sio.loadmat(dataset)\n",
    "    args.C = np.double(Problem['LAPL']) # euclidean distance matrix\n",
    "    args.p = np.int(Problem['d']) # number of data points\n",
    "    args.opt_val = Problem['opt_val'] # optimum value \n",
    "    X_true = Problem['X_true']\n",
    "\n",
    "    print(\"\\nDataset = {}. \\n\".format(dataset))\n",
    "    print(\"\\n f_opt = {}. \\n\".format(args.opt_val))\n",
    "\n",
    "    # Initialize\n",
    "    X = np.zeros((args.p,args.p))\n",
    "    \n",
    "    feasibility1 = [] # norm(A1(X)-b1)/norm(b1)\n",
    "    feasibility2 = [] # dist(X, \\mathcal{K})\n",
    "    objective    = [] # f(x)\n",
    "    cur_iter    = [] \n",
    "    t    = [] \n",
    "    \n",
    "    #u = np.zeros((N,1))\n",
    "    iter_track = np.unique(np.ceil(np.power(2, np.linspace(0,20,50))))\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    for iteration in range(1, maxit+1):\n",
    "        \n",
    "        # Update Step Size\n",
    "        gamma = ??\n",
    "        \n",
    "        # Update beta\n",
    "        beta_ = ??\n",
    "        \n",
    "        # Write down the vk to use in the lmo (eigenvalue routine)\n",
    "        (vk, feas_eq, feas_ineq) = grad_F(X, beta_, args)\n",
    "        # the above needs to be symmetric\n",
    "        \n",
    "        \n",
    "        # Linear minimization oracle\n",
    "        q, u = eigsh(??, k=1, tol=1e-16, which='SA')\n",
    "        if q >= 0:\n",
    "            X_bar = ??\n",
    "        else:\n",
    "            u = sqrt(args.p)*u\n",
    "            X_bar = np.outer(u,u)\n",
    "        \n",
    "        # Update X\n",
    "        X = (1.0 - gamma) * X + gamma * (X_bar)\n",
    "                \n",
    "        if any(iteration == iter_track) or iteration==maxit:\n",
    "            feasibility1.append(feas_eq)\n",
    "            feasibility2.append(feas_ineq)\n",
    "            objective.append(np.sum(args.C.flatten()*X.flatten()))\n",
    "            cur_iter.append(iteration)\n",
    "            t.append(time.time()-start)\n",
    "            print('{:03d} | {:.4e}| {:.4e}| {:.4e}|'.format(iteration, feasibility1[-1], feasibility2[-1],objective[-1]))\n",
    "            \n",
    "    return args, X_true, X, feasibility1, feasibility2, objective, cur_iter, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pick dataset\n",
    "#dataset = 'data/102n-insecta-ant-colony4-day10.mat'\n",
    "#dataset = 'data/55n-insecta-ant-colony1-day37.mat'\n",
    "dataset = 'lib/part3/data/25mammalia-primate-association-13.mat'\n",
    "\n",
    "args, X_true, X_HCGM, f1_HCGM, f2_HCGM, obj_HCGM, iter_HCGM, time_HCGM = HCGM(dataset, maxit=np.int(1e3), beta0=5e1)\n",
    "\n",
    "print(\"\\nHCGM finished. Running time: {} seconds.\".format(time_HCGM[-1]))\n",
    "\n",
    "plot_func(iter_HCGM, f1_HCGM, f2_HCGM, obj_HCGM, X_HCGM, X_true, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "<div id=\"refs\" class=\"references csl-bib-body hanging-indent\"\n",
    "role=\"doc-bibliography\">\n",
    "<div id=\"ref-arv\" class=\"csl-entry\" role=\"doc-biblioentry\">\n",
    "[@Arora2009] Arora, Sanjeev, Satish Rao, and Umesh Vazirani. 2009. <span>“Expander\n",
    "Flows, Geometric Embeddings and Graph Partitioning.”</span> <em>Journal\n",
    "of the ACM (JACM)</em> 56 (2): 5.\n",
    "</div>\n",
    "<div id=\"ref-chatziafratis2018hierarchical\" class=\"csl-entry\"\n",
    "role=\"doc-biblioentry\">\n",
    "[@Chatziafratis2018] Chatziafratis, Vaggos, Rad Niazadeh, and Moses Charikar. 2018.\n",
    "<span>“Hierarchical Clustering with Structural Constraints.”</span>\n",
    "<em>arXiv Preprint arXiv:1805.09476</em>.\n",
    "</div>\n",
    "<div id=\"ref-dasgupta2016cost\" class=\"csl-entry\" role=\"doc-biblioentry\">\n",
    "[@Dasgupta2016] Dasgupta, Sanjoy. 2016. <span>“A Cost Function for Similarity-Based\n",
    "Hierarchical Clustering.”</span> In <em>Proceedings of the Forty-Eighth\n",
    "Annual ACM Symposium on Theory of Computing</em>, 118–27.\n",
    "</div>\n",
    "<div id=\"ref-nr\" class=\"csl-entry\" role=\"doc-biblioentry\">\n",
    "[@Rossi2015] Rossi, Ryan A., and Nesreen K. Ahmed. 2015. <span>“The Network Data\n",
    "Repository with Interactive Graph Analytics and Visualization.”</span>\n",
    "In <em>AAAI</em>. <a\n",
    "href=\"http://networkrepository.com\">http://networkrepository.com</a>.\n",
    "</div>\n",
    "<div id=\"ref-vladarean2020conditional\" class=\"csl-entry\"\n",
    "role=\"doc-biblioentry\">\n",
    "[@Vladarean2020] Vladarean, Maria-Luiza, Ahmet Alacaoglu, Ya-Ping Hsieh, and Volkan\n",
    "Cevher. 2020. <span>“Conditional Gradient Methods for Stochastically\n",
    "Constrained Convex Minimization.”</span> In <em>International Conference\n",
    "on Machine Learning</em>, 9775–85. PMLR.\n",
    "</div>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
