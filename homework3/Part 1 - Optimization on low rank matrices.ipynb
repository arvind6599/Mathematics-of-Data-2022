{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4132675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use these libraries later in the exercise\n",
    "#%pip install numpy scipy matplotlib\n",
    "# if you get import errors, you might have to install these two librarires\n",
    "#%pip install PyWavelets\n",
    "#%pip install opencv-python\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "# general math and science operations\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "# loading the data \n",
    "import scipy.io \n",
    "from scipy.sparse import csr_matrix \n",
    "from scipy.sparse import linalg\n",
    "\n",
    " # timing\n",
    "from time import time\n",
    " # pretty progress bars\n",
    "from tqdm.notebook import trange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a997e534",
   "metadata": {},
   "source": [
    "We have seen in the lectures that given an optimization task whose iterates live on a  convex subset $\\mathcal{X} \\subset \\mathbb{R}^n$ we can ensure the iterates of our algorithms stay within $\\mathcal{X}$ in one of two ways. \n",
    "\n",
    "In the first way, we use projections, computed via the proximal operator $\\text{prox}_{\\delta_\\mathcal{X}}$ . In the second way, we use linear minimization oracles  $\\text{lmo}_\\mathcal{X}$ within a conditional gradient framework\n",
    "that take simplicial combinations of elements from the set X whereby producing iterates remaining in $\\mathcal{X}$.\n",
    "\n",
    "The following exercises will help you understand what kind of computations are involved for each of these two operators, and how their computational complexity compares. For this we will work with $\\mathcal{X}$ being the set of low-rank matrices defined via the nuclear norm ball $\\mathcal{X}=\\lbrace X:X\\in \\mathbb{R}^{p\\times n}, \\Vert X  \\Vert_* \\leq \\kappa \\rbrace$ with $\\kappa$ being the radius of the zero-centered nuclear norm ball.\n",
    "\n",
    "We will first mathematically study properties of  the proximal operator $\\text{prox}_{\\delta_\\mathcal{X}}$  (**1.1** ) and the linear minimization oracles $\\text{lmo}_\\mathcal{X}$ (**1.2**) onto this $\\mathcal{X}$ and then compare them empirically by implementing movie recommender system (**1.3**) and image deblurring (**1.4**) algorithms.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34393988",
   "metadata": {},
   "source": [
    "# 1.1 Computing projections onto $\\mathcal{X}$\n",
    "\n",
    "\n",
    "## 1.1.1 (2 pts)\n",
    "\n",
    "Recall that given a set $\\mathcal{X} \\subset \\mathbb{R}^{p \\times m}$, its corresponding\n",
    "    projection operator is given by\n",
    "    $\\mathrm{proj}_{\\mathcal{X}} (\\boldsymbol{Z}) = \\mathop{\\mathrm{arg\\,min}}\\limits_{{\\bf X}\\in \\mathcal{X}}\\{ \\|{\\bf X}- \\boldsymbol{Z}\\|_F^2\\}, \\; \\forall \\boldsymbol{Z}\\in  \\mathbb{R}^{p \\times m}$.\n",
    "    Using the definition of the proximal operator given in class, show\n",
    "    the equivalence between the projection operator and the proximal\n",
    "    operator:\n",
    "    $$\\mathrm{proj}_{\\mathcal{X}} (\\boldsymbol{Z})  = \\mathrm{prox}_{\\delta_{\\mathcal{X}}}(\\boldsymbol{Z}),$$\n",
    "    where $\\delta_{\\mathcal{X}}$ is the indicator function of\n",
    "    $\\mathcal{X}$ i.e.  $\\delta_{\\mathcal{X}}({\\bf Y}) = \\begin{cases} 0, \\text{ if } {\\bf Y}\\in \\mathcal{X} \\\\ +\\infty, \\text{ o.w. } \\end{cases}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6b900b",
   "metadata": {},
   "source": [
    "## ANS 1.1.1:  \n",
    "\n",
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cda554",
   "metadata": {},
   "source": [
    "## 1.1.2 (3 pts)\n",
    "\n",
    "The projection operator of convex sets has an interesting and useful property: it is non-expansive. Mathematically, we write:\n",
    "$$\n",
    "        \\|\\mathrm{proj}_{\\mathcal{X}} (\\textbf{x}) - \\mathrm{proj}_{\\mathcal{X}} (\\textbf{y})\\| \\leq \\|\\textbf{x}- \\textbf{y}\\|, \\forall \\textbf{x}, \\textbf{y}\\in \\mathbb{R}^p, \\tag{1}\\label{eq:non-expansivity}\n",
    "$$\n",
    "where $\\|\\cdot\\|$ denotes the usual Euclidean norm\n",
    "and $\\mathcal{X}$ is a non-empty, closed and convex set. For keeping\n",
    "things simple, in this point we use the space of vectors\n",
    "$\\mathbb{R}^p$ in which $\\mathcal{X} \\in \\mathbb{R}^p$ is a closed\n",
    "convex set.\n",
    "\n",
    "Informally, \\eqref{eq:non-expansivity} means that the distance between the\n",
    "*projections* of the two points onto $\\mathcal{X}$ will be *no\n",
    "greater* than the distance between the points themselves.\n",
    "Conversely, for non-convex sets, this does not hold (you can try\n",
    "building a counterexample for a doughnut-shaped set).\n",
    "\n",
    "Prove inequalityÂ \\eqref{eq:non-expansivity} starting from the equivalent\n",
    "characterization of the Euclidean projection:\n",
    "$\\textbf{z}^* = \\mathrm{proj}_{\\mathcal{X}} (\\textbf{x}) \\iff \\langle \\textbf{x}- \\textbf{z}^*, \\textbf{z}- \\textbf{z}^*\\rangle \\leq 0, \\, \\forall \\textbf{z}\\in \\mathcal{X}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750d532c",
   "metadata": {},
   "source": [
    "## ANS 1.1.2\n",
    "\n",
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75b88e3",
   "metadata": {},
   "source": [
    "## 1.1.3.  (4 pts)\n",
    "\n",
    "Let ${\\boldsymbol Z}= {\\boldsymbol U}\\boldsymbol{\\Sigma} {\\boldsymbol V}^\\top$\n",
    "    be the singular value decomposition of\n",
    "    ${\\boldsymbol Z}\\in \\mathbb{R}^{p \\times m}$. Denote the diagonal of\n",
    "    $\\boldsymbol{\\Sigma} \\in \\mathbb{R}^{s \\times s}$ by a vector\n",
    "    $\\sigma \\in \\mathbb{R}^{s}$, where $s = \\min \\{ p, m \\}$. Let\n",
    "    $\\sigma^{\\ell_1}$ be the projection of $\\sigma$ onto the\n",
    "    $\\ell_1$-norm ball\n",
    "    $\\{ \\textbf{x}: \\textbf{x}\\in \\mathbb{R}^{s} , \\left\\Vert  \\textbf{x} \\right\\Vert_1 \\leq \\kappa  \\}$\n",
    "    with radius $\\kappa$. Show that the projection of this matrix onto\n",
    "    the nuclear norm ball\n",
    "    $\\mathcal{X} = \\{ {\\boldsymbol X}: {\\boldsymbol X}\\in \\mathbb{R}^{p \\times m} , \\| {\\boldsymbol X}\\|_\\ast \\leq \\kappa \\}$\n",
    "    can be computed by projecting $\\sigma$ onto the $\\ell_1$ norm ball,\n",
    "    i.e.,\n",
    "    $$\\mathrm{proj}_\\mathcal{X} ({\\boldsymbol Z}) = {\\boldsymbol U}\\boldsymbol\\Sigma^{\\ell_1} {\\boldsymbol V}^\\top,$$\n",
    "    where $\\Sigma^{\\ell_1} \\in \\mathbb{R}^{s \\times s}$ denotes the\n",
    "    diagonal matrix with diagonal $\\sigma^{\\ell_1}$.\n",
    "\n",
    "(Hint: Use Mirsky's inequality:\n",
    "    $\\| {\\boldsymbol X}- {\\boldsymbol Z}\\|_F \\geq \\| \\boldsymbol{\\Sigma}_{{\\boldsymbol X}} - \\boldsymbol{\\Sigma}_{{\\boldsymbol Z}}\\|_F$,\n",
    "    where\n",
    "    $\\boldsymbol{\\Sigma}_{{\\boldsymbol X}}, \\boldsymbol{\\Sigma}_{{\\boldsymbol Z}} \\in \\mathbb{R}^{s \\times s}$\n",
    "    are the diagonal matrices of the singular values of\n",
    "    ${\\boldsymbol X}, {\\boldsymbol Z}$ respectively.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f3d656",
   "metadata": {},
   "source": [
    "##    ANS 1.1.3: \n",
    "\n",
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dfb3f8",
   "metadata": {},
   "source": [
    "# 1.2 (4 pts): Computing the linear minimization oracle of $\\mathcal{X}$\n",
    "\n",
    "\n",
    "Problem 1.1 shows that projection onto the nuclear norm ball requires\n",
    "computing the singular value decomposition. The computational complexity\n",
    "of the singular value decomposition is $\\mathcal{O}(\\min(m^2p,mp^2))$,\n",
    "which can easily become a computational bottleneck if $m$ or $p$ are\n",
    "large. This bottleneck increased the popularity of algorithms that\n",
    "leverage the linear minimization oracle (lmo) instead (e.g.,\n",
    "[Jaggi2013](https://proceedings.mlr.press/v28/jaggi13.html), [yurtsever2018](http://proceedings.mlr.press/v80/yurtsever18a)):\n",
    "$$\\text{lmo}_{\\mathcal{X}}({\\boldsymbol Z})  = \\arg \\min_{{\\boldsymbol X}\\in \\mathcal{X}} \\langle {\\boldsymbol X},{\\boldsymbol Z}\\rangle \\qquad \\text{where}\\qquad \\langle {\\boldsymbol X},{\\boldsymbol Z}\\rangle = \\text{Tr}({\\boldsymbol Z}^\\top{\\boldsymbol X}).$$\n",
    "Note that $\\text{lmo}_\\mathcal{X}({\\boldsymbol Z})$ is not single valued\n",
    "in general. With abuse of terminology, when we say that we compute the\n",
    "lmo, we actually mean that we compute an instance ${\\boldsymbol X}$ such\n",
    "that ${\\boldsymbol X}\\in \\text{lmo}_\\mathcal{X}({\\boldsymbol Z})$.\n",
    "\n",
    "Show that the lmo$_\\mathcal{X}$ when $\\mathcal{X}$ is the nuclear norm\n",
    "ball:\n",
    "$\\mathcal{X} = \\{ {\\boldsymbol X}: {\\boldsymbol X}\\in \\mathbb{R}^{p \\times m} , \\| {\\boldsymbol X}\\|_\\ast \\leq \\kappa \\}$\n",
    "gives the following output:\n",
    "$$-\\kappa ~ \\! \\mathbf{u}\\mathbf{v}^T   \\in  \\text{lmo}_{{\\mathcal{X}}}({\\boldsymbol Z}) ,$$\n",
    "where $\\mathbf{u}$ and $\\mathbf{v}$ are the left and right singular\n",
    "vectors that correspond to the largest singular value of\n",
    "${\\boldsymbol Z}$.\n",
    "\n",
    "(Hint: By definition\n",
    "$\\kappa ~ \\! \\mathbf{u}\\mathbf{v}^T \\in \\mathcal{X}$. You just need to\n",
    "show\n",
    "$\\langle {\\boldsymbol X},{\\boldsymbol Z}\\rangle \\geq \\langle -\\kappa ~ \\! \\mathbf{u}\\mathbf{v}^T,{\\boldsymbol Z}\\rangle$\n",
    "for all ${\\boldsymbol X}\\in \\mathcal{X}$.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712f1d86",
   "metadata": {},
   "source": [
    "# ANS 1.2: \n",
    "\n",
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb5cc02",
   "metadata": {},
   "source": [
    "# 1.3 (8 pts): Comparing the scalability of $\\mathrm{proj}_{\\mathcal{X}} (\\boldsymbol{Z})$ and $\\mathrm{lmo}_{\\mathcal{X}} (\\boldsymbol{Z})$\n",
    "\n",
    "In this exercise, we will compare the execution time of\n",
    "$\\mathrm{proj}_{\\mathcal{X}} (\\boldsymbol{Z})$ and\n",
    "$\\mathrm{lmo}_{\\mathcal{X}} (\\boldsymbol{Z})$ on two datasets provided\n",
    "to you in the codes. These datasets consist of the ratings given by\n",
    "MovieLens users to movies in a given list. The 100k dataset consists of\n",
    "100,000 ratings from 1000 users on 1700 movies. The 1M dataset consists\n",
    "of 1 million ratings from 6000 users on 4000 movies.\n",
    "\n",
    "As you likely figured out already from the numbers above, users do not\n",
    "rate all of the movies, and therefore, we model the ratings as entries\n",
    "of a low-rank matrix, where rows correspond to different users and\n",
    "columns correspond to different movies. A classical task in machine\n",
    "learning is to predict the value of the missing entries, which is called\n",
    "the matrix completion problem.\n",
    "\n",
    "Many other tasks can be formulated as convex minimization problems,\n",
    "constrained to the nuclear-norm ball, which captures a low rank model\n",
    "since it is the atomic norm of rank-1 matrices (see Lecture 4). A good\n",
    "optimization algorithm must ensure feasibility in a scalable way: For\n",
    "instance, the famous Netflix competition data consists of 100480507\n",
    "ratings that 480189 users gave to 17770 movies (much bigger than the\n",
    "datasets above). Projecting a matrix of this size onto the nuclear-norm\n",
    "ball is indeed demanding.\n",
    "\n",
    "### 1.3.1.  (4 pts)\n",
    "\n",
    "Implement the projection operator as a function called `proj_nuc` below. You can use the helper function `proj_L1` we define here from the `projL1.py` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46ccd2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.part1.projL1 import projL1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267714eb",
   "metadata": {},
   "source": [
    "Set $\\kappa = 5000$ and measure the computation time of the\n",
    "    projection operator with the 100k and the 1M MovieLens dataset using our provided helper code, which loads the datasets, constructs the data matrix, and times the evaluation of\n",
    "    the projection operator. Write the values you get in a markdown cell.\n",
    "    Run set `NUM_TIMES` 5 times and report the average timing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8858303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def projNuc(Z, kappa):\n",
    "    #PROJNUC This function implements the projection onto nuclear norm ball.\n",
    "    \n",
    "    raise NotImplementedError(\"your code here\")\n",
    "    \n",
    "    return proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db35b990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_completion(path,proj_func,num_times,kappa=5000):\n",
    "    \"\"\"\n",
    "    This helper functions loads the data for you, arranges it into the suitable vector form and then\n",
    "    runs the timing on the provided projection or lmo\n",
    "    \"\"\"\n",
    "    data = scipy.io.loadmat(path)\n",
    "    Rating = data['Rating'].flatten()\n",
    "    UserID = data['UserID'].flatten() - 1  # Python indexing starts from 0 whereas Matlab from 1\n",
    "    MovID = data['MovID'].flatten() - 1    # Python indexing starts from 0 whereas Matlab from 1\n",
    "\n",
    "    nM = np.amax(data['MovID'])\n",
    "    nU = np.amax(data['UserID'])\n",
    "    total=0\n",
    "    Z = csr_matrix((Rating, (MovID, UserID)),shape=(nM, nU),dtype=float).toarray()\n",
    "    for _ in trange(NUM_TIMES):\n",
    "        tstart = time()\n",
    "        Z_proj = proj_func(Z, kappa)\n",
    "        elapsed = time() - tstart\n",
    "        total+=elapsed/NUM_TIMES\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c89219f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "367922d12a724477bc29075a8f27108c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NotImplementedError",
     "evalue": "your code here",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m data \u001b[38;5;241m=\u001b[39m scipy\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mloadmat(PATH100K)  \u001b[38;5;66;03m# load 100k dataset\u001b[39;00m\n\u001b[1;32m      4\u001b[0m NUM_TIMES\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m\n\u001b[0;32m----> 5\u001b[0m total\u001b[38;5;241m=\u001b[39m\u001b[43meval_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPATH100K\u001b[49m\u001b[43m,\u001b[49m\u001b[43mprojNuc\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_TIMES\u001b[49m\u001b[43m,\u001b[49m\u001b[43mkappa\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkappa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproj for 100k data takes \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m sec\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(total))\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36meval_completion\u001b[0;34m(path, proj_func, num_times, kappa)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m trange(NUM_TIMES):\n\u001b[1;32m     16\u001b[0m     tstart \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m---> 17\u001b[0m     Z_proj \u001b[38;5;241m=\u001b[39m \u001b[43mproj_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mZ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkappa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     elapsed \u001b[38;5;241m=\u001b[39m time() \u001b[38;5;241m-\u001b[39m tstart\n\u001b[1;32m     19\u001b[0m     total\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39melapsed\u001b[38;5;241m/\u001b[39mNUM_TIMES\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mprojNuc\u001b[0;34m(Z, kappa)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprojNuc\u001b[39m(Z, kappa):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m#PROJNUC This function implements the projection onto nuclear norm ball.\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour code here\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m proj\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: your code here"
     ]
    }
   ],
   "source": [
    "kappa = 5000\n",
    "PATH100K='./lib/part1/dataset/ml-100k/ub_base'\n",
    "data = scipy.io.loadmat(PATH100K)  # load 100k dataset\n",
    "NUM_TIMES=5\n",
    "total=eval_completion(PATH100K,projNuc,num_times=NUM_TIMES,kappa=kappa)\n",
    "print('proj for 100k data takes {} sec'.format(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ce991cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f5f5e5a77c44feeabec3dc24f309897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NotImplementedError",
     "evalue": "your code here",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m PATH1M\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./lib/part1/dataset/ml-1m/ml1m_base\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      5\u001b[0m kappa \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5000\u001b[39m\n\u001b[0;32m----> 8\u001b[0m total\u001b[38;5;241m=\u001b[39m\u001b[43meval_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPATH1M\u001b[49m\u001b[43m,\u001b[49m\u001b[43mprojNuc\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_TIMES\u001b[49m\u001b[43m,\u001b[49m\u001b[43mkappa\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkappa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproj for 1M data takes \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m sec\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(total))\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36meval_completion\u001b[0;34m(path, proj_func, num_times, kappa)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m trange(NUM_TIMES):\n\u001b[1;32m     16\u001b[0m     tstart \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m---> 17\u001b[0m     Z_proj \u001b[38;5;241m=\u001b[39m \u001b[43mproj_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mZ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkappa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     elapsed \u001b[38;5;241m=\u001b[39m time() \u001b[38;5;241m-\u001b[39m tstart\n\u001b[1;32m     19\u001b[0m     total\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39melapsed\u001b[38;5;241m/\u001b[39mNUM_TIMES\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mprojNuc\u001b[0;34m(Z, kappa)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprojNuc\u001b[39m(Z, kappa):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m#PROJNUC This function implements the projection onto nuclear norm ball.\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour code here\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m proj\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: your code here"
     ]
    }
   ],
   "source": [
    "NUM_TIMES=5\n",
    "# path to  1M dataset\n",
    "# NOTE: This one can take few minutes!\n",
    "PATH1M='./lib/part1/dataset/ml-1m/ml1m_base'\n",
    "kappa = 5000\n",
    "\n",
    "\n",
    "total=eval_completion(PATH1M,projNuc,num_times=NUM_TIMES,kappa=kappa)\n",
    "print('proj for 1M data takes {} sec'.format(total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88210fc",
   "metadata": {},
   "source": [
    "###    ANS 1.3.1: \n",
    "**Replace this with your timing.**\n",
    "\n",
    "On my computer for 100k and 1M data, I get\n",
    "    $\\approx0.42$ and $\\approx28$\n",
    "    seconds respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc59c97",
   "metadata": {},
   "source": [
    "### 1.3.2.  (4 pts)\n",
    "\n",
    "Implement the lmo with ${\\mathcal{X}}$ as a function called\n",
    "    `lmo_nuc`  below. Set again $\\kappa = 5000$ and measure the\n",
    "    computation time for the 100k and 1M Movielens datasets. Compare these values with\n",
    "    the computation time of the projection operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf80bb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpNuc(Z, kappa):\n",
    "    #SHARPNUC This function implements the sharp operator for the nuclear norm ball constraint. .\n",
    "    \n",
    "    raise NotImplementedError(\"your code here\")\n",
    "    \n",
    "    return lmo_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc756d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "kappa = 5000\n",
    "total=eval_completion(PATH100K,sharpNuc,num_times=NUM_TIMES,kappa=kappa)\n",
    "print('lmo for 100k data takes {} sec'.format(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c899705e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kappa = 5000\n",
    "total=eval_completion(PATH1M,sharpNuc,num_times=NUM_TIMES,kappa=kappa)\n",
    "\n",
    "print('lmo for 1M data takes {} sec'.format(total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90eb1296",
   "metadata": {},
   "source": [
    "### ANS 1.3.2:\n",
    "**Replace this with your timing.**\n",
    "On my computer for 100k and 1M data, I get\n",
    "    $\\approx0.015$ and $\\approx0.25$\n",
    "    seconds respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd53be50",
   "metadata": {},
   "source": [
    "# 1.4 (19 pts): Frank-Wolfe for blind image deblurring\n",
    "\n",
    "You are working with the local police to help identify a license plate\n",
    "of a car involved in a crime scene investigation. Unfortunately, the\n",
    "CCTV image of the car is blurry. In this exercise, we simulate this\n",
    "scenario with a deblurred license plate image found from the\n",
    "internet.\n",
    "\n",
    "Deblurring is an instance of the blind deconvolution problem: Given two\n",
    "unknown vectors $\\textbf{x},  {\\boldsymbol w}\\in \\mathbb{R}^L$, we\n",
    "observe their circular convolution\n",
    "$\\textbf{y}=  {\\boldsymbol w}*\\textbf{x}$, i.e.,\n",
    "$$y_\\ell = \\sum_{\\ell'=1}^L w_{\\ell'} x_{\\ell - \\ell' + 1},$$ where the\n",
    "index $\\ell - \\ell' + 1$ in the sum is understood to be modulo $L$.\n",
    "\n",
    "Blind deconvolution seeks to separate ${\\boldsymbol w}$ and\n",
    "$\\textbf{x}$, given $\\textbf{y}$. The operative word *blind* comes from\n",
    "the fact that we do not have much prior information about the signals.\n",
    "In this case, what we can assume is that ${\\boldsymbol w}$ and\n",
    "$\\textbf{x}$ belong to *known* subspaces of $\\mathbb{R}^L$ of dimension\n",
    "$K$ and $N$, i.e., we write $$\\begin{aligned}\n",
    "{\\boldsymbol w}&= {\\boldsymbol B}{\\boldsymbol h}, \\quad {\\boldsymbol h}\\in \\mathbb{R}^K \\\\\n",
    "\\textbf{x}&= {\\boldsymbol C}{\\boldsymbol m}, \\quad {\\boldsymbol m}\\in \\mathbb{R}^N\n",
    "\\end{aligned}$$ for some $L \\times K$ matrix ${\\boldsymbol B}$ and\n",
    "$L \\times N$ matrix ${\\boldsymbol C}$. The columns of these matrices\n",
    "form bases for the subspaces in which ${\\boldsymbol w}$ and $\\textbf{x}$\n",
    "live.\n",
    "\n",
    "As we have seen in Homework 1, natural images have sparse wavelet\n",
    "expansions. Hence, the image $\\textbf{x}$ can be expressed as\n",
    "$\\textbf{x}= {\\boldsymbol C}{\\boldsymbol m}$ with ${\\boldsymbol C}$ is\n",
    "the matrix formed by a subset of the columns of the wavelet transform\n",
    "matrix. In addition, the blur kernel ${\\boldsymbol w}$ is typically due\n",
    "to simple or \"sparse\" motion, which can be written as\n",
    "${\\boldsymbol w}= {\\boldsymbol B}{\\boldsymbol h}$ with ${\\boldsymbol B}$\n",
    "is the matrix formed by a subset of the columns of the identity matrix.\n",
    "\n",
    "In deblurring, $\\textbf{x}$ corresponds to the image we want to recover\n",
    "(i.e., the license plate) and ${\\boldsymbol w}$ to a 2D blur kernel.\n",
    "Thus, the 2D convolution $\\textbf{y}=  {\\boldsymbol w}*\\textbf{x}$\n",
    "produces a blurred image. We assume that we know or can estimate the\n",
    "support of the blur kernel (i.e., the location of its nonzero elements).\n",
    "In real applications, the support can be estimated by an expert using\n",
    "the physical information such as the distance of object to the focus and\n",
    "the camera, the speed of the camera and/or the object, camera shutter\n",
    "speed, etc.\n",
    "\n",
    "In this experiment, we use a very rough estimate for the support - a box\n",
    "at the center of the domain, whose size we have roughly tuned.\n",
    "Interestingly, it is possible to make the plate readable even in this\n",
    "setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b388a9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from lib.part1.deblur_lib import setup_show\n",
    "setup_show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5816b8",
   "metadata": {},
   "source": [
    "###  Reformulating the problem\n",
    "\n",
    "We now reformulate the blind image deconvolution problem, so that we can\n",
    "apply the constrained optimization algorithms we have seen in the\n",
    "course. Let ${\\boldsymbol b}$ be the $L$-point normalized discrete\n",
    "Fourier transform (DFT) of the observation $\\textbf{y}$, i.e,\n",
    "${\\boldsymbol b}= \\mathbf{F} \\textbf{y}$, where $F$ is the DFT matrix.\n",
    "Then, ${\\boldsymbol b}$ can be written as\n",
    "${\\boldsymbol b}= {\\boldsymbol A}({\\bf X})$ where\n",
    "${\\bf X}= {\\boldsymbol h}{\\boldsymbol m}^\\top$ and ${\\boldsymbol A}$ is\n",
    "a linear operator. Explicit expression of this linear operator\n",
    "${\\boldsymbol A}$ is out of the scope of this homework, c.f.,\n",
    "[ahmed2014](https://ieeexplore.ieee.org/document/6680763/) for further details. This reformulation allows us to\n",
    "express $\\textbf{y}$, which is a nonlinear combination of the\n",
    "coefficients of ${\\boldsymbol h}$ and ${\\boldsymbol m}$, as a linear\n",
    "combination of the entries of their outer product\n",
    "${\\bf X}= {\\boldsymbol h}{\\boldsymbol m}^\\top$. Note that given\n",
    "${\\boldsymbol B}$ and ${\\boldsymbol C}$, recovering ${\\boldsymbol m}$\n",
    "and ${\\boldsymbol h}$ from ${\\boldsymbol b}$ is the same as recovering\n",
    "$\\textbf{x}$ and ${\\boldsymbol w}$ from $\\textbf{y}$.\n",
    "\n",
    "Since ${\\bf X}$ is a rank one matrix, we can use the nuclear norm to\n",
    "enforce approximately low-rank solutions. Then, we can formulate the\n",
    "blind deconvolution problem as follows:\n",
    "$${\\boldsymbol X}^\\star \\in \\arg \\min_{ {\\boldsymbol X}} \\bigg\\{ \\frac{1}{2} \\| \\mathbf{A}({\\boldsymbol X}) - {\\boldsymbol b}\\|_2^2 :  \\| {\\boldsymbol X}\\|_\\ast \\leq \\kappa, ~{\\boldsymbol X}\\in \\mathbb{R}^{p\\times m}   \\bigg\\}, \\tag{4}\\label{eq:FWform}$$\n",
    "where $\\kappa > 0$ is a tuning parameter.\n",
    "\n",
    "Note that our problem is constrained to the nuclear norm ball\n",
    "$\\mathcal{X} = \\{ {\\boldsymbol X}: {\\boldsymbol X}\\in \\mathbb{R}^{p \\times m} , \\| {\\boldsymbol X}\\|_\\ast \\leq \\kappa \\}$.\n",
    "\n",
    "We will apply the Frank-Wolfe algorithm to solve the optimization\n",
    "problem given in \\eqref{eq:FWform}. The Frank-Wolfe algorithm is one of the earliest\n",
    "algorithms that avoids projections. Instead of projections, it leverages\n",
    "lmos (for a very good survey see [Jaggi2013](https://proceedings.mlr.press/v28/jaggi13.html)):\n",
    "$$\\mathrm{lmo}(\\nabla f ({\\boldsymbol Z})) = \\arg \\min_{{\\boldsymbol X}\\in \\mathcal{X}} ~ \\langle \\nabla f ({\\boldsymbol Z}), {\\boldsymbol X}\\rangle,$$\n",
    "where\n",
    "$\\mathcal{X} = \\{ {\\boldsymbol X}: \\| {\\boldsymbol X}\\|_\\ast \\leq \\kappa, ~{\\boldsymbol X}\\in \\mathbb{R}^{p\\times m} \\}$\n",
    "as in Part 1. It applies to the generic constrained minimization\n",
    "template with a smooth objective function,\n",
    "$\\min_{\\boldsymbol X}\\{ f({\\boldsymbol X}) : {\\boldsymbol X}\\in \\mathcal{X}, \\, \\mathcal{X} \\text{ - convex, compact}  \\}$\n",
    "as follows:\n",
    "\n",
    "----\n",
    "\n",
    "\n",
    "###  Frank-Wolfe's algorithm\n",
    "\n",
    "1.Â Choose ${\\boldsymbol X}^0 \\in\\mathcal{X}$.\n",
    "\n",
    "2.Â For $k=0, 1, \\ldots$ perform:\n",
    "      $$\\begin{cases}\n",
    "      \\hat{{\\bf X}}^k &:= \\mathrm{lmo}(\\nabla f ({\\boldsymbol X}^k)), \\\\\n",
    "      {\\bf X}^{k+1} &:= (1-\\gamma_k){\\bf X}^k + \\gamma_k\\hat{{\\bf X}}^k,\n",
    "      \\end{cases}$$ where $\\gamma_k := {2}/{(k+2)}$.\n",
    "\n",
    "---\n",
    "\n",
    "### 1.4.1.  (4 pts)\n",
    "\n",
    "Recall that the Frank-Wolfe algorithm applies only for\n",
    "    smooth objectives. Show that the objective function is smooth in the sense its gradient is Lipschitz continuous."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d723d8",
   "metadata": {},
   "source": [
    "### ANS 1.4.1\n",
    "The gradient of the objective function is $A^T( A(X) - b)$, where\n",
    "    $A^T$ is the adjoint linear operator of $A$. $$\\begin{aligned}\n",
    "    \\| A^T( A(X) - b) - A^T( A(Y) - b)\\|_F &= \\| A^T(A( X- Y)) \\|_F \\\\\n",
    "    &\\leq \\| A^TA\\| \\|X - Y\\|_F.\n",
    "    \\end{aligned}$$ Hence, the gradient is Lipschitz continuous with\n",
    "    $L = \\| A^TA\\| := \\max_{X} \\frac{\\|A^T(A(X)) \\|_F}{\\|X\\|_F }$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d740f510",
   "metadata": {},
   "source": [
    "### 1.4. 2.  (15 pts)\n",
    "\n",
    "Complete the missing lines of the `frank_wolfe` function.\n",
    "We provide you the linear operators that you need to compute the lmo in the code. Note that we do not need to\n",
    "    store and use the linear operator ${\\boldsymbol A}$ in the ambient\n",
    "    dimensions. In fact, for storage and arithmetic efficiency, we\n",
    "    should avoid explicitly writing ${\\boldsymbol A}$. You can find more\n",
    "    details about this aspect as comments in the code.\n",
    "\n",
    "Tune the. \n",
    "    parameter $\\kappa$ until the license plate number becomes readable.\n",
    "    What is the license plate number? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c650cf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.part1.deblur_lib import Aoper,AToper,plot_func,b,kernelsize,imsize,LinearOperator,svds,Cop,x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e3af11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frank_wolfe(Aoper, AToper, b, n1, n2, kappa, maxit, plotFunc):\n",
    "# PURPOSE: We will solve the following problem formulation with\n",
    "# Frank-Wolfe's method.                                    \n",
    "#                   min_x  0.5*norm(A(x) - b)^2        \n",
    "#                   s.t.:  norm_nuc(x) <= kappa,     \n",
    "#\n",
    "# Laboratory for Information and Inference Systems (LIONS)\n",
    "# Ecole Polytechnique Federale de Lausanne (EPFL) - SWITZERLAND\n",
    "    \n",
    "    # Print the caption\n",
    "    \n",
    "    #Initialize \n",
    "    AX_t = 0.0   # zeros\n",
    "    X = 0.0      # zeros\n",
    "    \n",
    "    # keep track of objective value\n",
    "    fx = np.array([])\n",
    "        \n",
    "    # The main loop    \n",
    "    bar=trange(0, maxit+1)\n",
    "    for iteration in bar:\n",
    "        \n",
    "        # Print the objective values ...\n",
    "        fx = np.append(fx, 0.5*np.linalg.norm(AX_t - b,2)**2)\n",
    "        bar.set_description('{:03d} | {:.4e}'.format(iteration, fx[-1]))\n",
    "\n",
    "        # Form the residual and fix the operator to be used in svds.\n",
    "        res_cur = AX_t - b\n",
    "        \n",
    "        ATop1 = lambda w: AToper[\"matvec\"](raise NotImplementedError(\"Complete me\"),w) # Fill\n",
    "        ATop2 = lambda w: AToper[\"rmatvec\"]( raise NotImplementedError(\"Complete me\"),w) # Fill\n",
    "        \n",
    "        svdsArg = LinearOperator((n2,n1), matvec=ATop1, rmatvec=ATop2)\n",
    "        topLe_vec, singVal, topRe_vec = svds(svdsArg, k=1, tol=1e-4, which='LM')\n",
    "        # Note: we could also used svds. Lansvd and svds solve the same problem with similar\n",
    "        # but different approaches. Svds in older versions of Matlab does not accept function\n",
    "        # handles as inputs, this is why we rather used lansvd here. If you run into trouble\n",
    "        # with lansvd on your computer, try to use svds (with properly modifying the inputs)\n",
    "        \n",
    "        # Apply A to the rank 1 update\n",
    "        AXsharp_t = Aoper(topLe_vec, -kappa, topRe_vec.T)\n",
    "        \n",
    "        \n",
    "        # Step size\n",
    "        weight=  raise NotImplementedError(\"Complete me\") # Fill\n",
    "\n",
    "        \n",
    "        # Update A*X\n",
    "        AX_t = (1.0-weight)*AX_t + weight*(AXsharp_t)\n",
    "        \n",
    "        # Update X\n",
    "        X = raise NotImplementedError(\"Complete me\") # Fill\n",
    "        \n",
    "        # Show the reconstruction (at every 10 iteration) \n",
    "        if iteration%10==0:\n",
    "            U,S,V = np.linalg.svd(X,full_matrices=0,compute_uv=1)\n",
    "            plotFunc(U[:,0],iteration)\n",
    "\n",
    "    return X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a3fdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Frank-Wolfe's method\n",
    "MaxIters = 200\n",
    "kappa = 1000\n",
    "plotF = lambda m,it: plot_func(m,it,Cop,x)\n",
    "xFW = frank_wolfe(Aoper, AToper, b, kernelsize, imsize, kappa, MaxIters, plotF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419eb9b5",
   "metadata": {},
   "source": [
    "### ANS 1.4.2\n",
    "With kappa=???, we obtain the\n",
    "    following image, from which we can read the plate **???**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6534e9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
